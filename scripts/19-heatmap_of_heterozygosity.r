print("this is EDA code, pull from here to do the het by distance and location stuff.")

#pull the map and the Q subsetting from the admixture file
#the heterozygosity stuff from the EDA below










#######################################################
# old EDA code as starting point, 
# See notes on:
# New method to quantify climactic differences
# Go through the plan there, looking at if all the requesite data are available, if
# so then set up a subfolder here and get to work on generating the data and 
# using it to conduct the analyses.

#######
# location
####### 
setwd("C:/Users/camnu/bin/salmon-genomic-vulnerability/scripts")

#######
# libraries
####### 

library(tidyverse)
library(FactoMineR)
library(factoextra)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)

#######
# functions
####### 


#######
# genetic response variable
####### 

print("stand in for the final response variable")
print("would want the per location mean heterozygosity I think")
print("would this be effected by sammple size?")

clustered_full_data_PCA = read_tsv( "../data/interim/full_data_PCA_kmeans_cluster_info.tsv")
climate_vars = c("Minimum.Air.Temperature", "Air.Temperature",        "Maximum.Air.Temperature", "Total.Precipitation",
                 "Dew.Point.Temperature",  "Relative.Humidity",     "Wind.Direction",        "Solar.Radiation",    
                 "Atmospheric.Pressure",  "Snow.Precipitation",      "Snow.Depth.Accumulation", "Snow.Water.Equivalent",
                 "Wind.Speed.at.2.meters") 



################################################################################
################################################################################
################################################################################
#######
# per location trend calculations
####### 

diff_days = function(year, month, day, baseline = "1979-12-31"){
  as.numeric(difftime(paste0(year, "-", month,"-", day), baseline , units = "days"))
}

## This was run, can start with the saved version to save time.
#climate_df = read_csv("../data/raw/ClimateDataSalmon_1980_2022.csv")
#climate_df$time_series_x = unlist(lapply(1:nrow(climate_df), function(i){
#  diff_days(climate_df$Year[[i]], climate_df$Month[[i]], climate_df$Day[[i]])
#}))
#write_csv(climate_df, "../data/raw/MODDED_ClimateDataSalmon_1980_2022.csv")

climate_df = read_csv("../data/raw/MODDED_ClimateDataSalmon_1980_2022.csv")


trend_df = data.frame()

#location = "ENG"
for (location in unique(climate_df$Name)){
  print(paste0("on location: ", location))
  #has the per day info for 1980 - 2022
  sub_df = climate_df[climate_df$Name == location,]
  
  location_trends = data.frame()
  #clim_var = "Air.Temperature"
  for(clim_var in climate_vars){
    print(paste0("on variable: ", clim_var))
    #put the given variable into the formula
    assoc_test = lm(as.formula(paste0(clim_var, "~time_series_x")), sub_df)
    
    intercept = assoc_test$coefficients[[2]]
    slope = assoc_test$coefficients[[2]]
    
    trends = data.frame(clim_var = clim_var, intercept = intercept, slope = slope)
    location_trends = rbind(location_trends, trends)
  }
  location_trends$location = location
  
  trend_df = rbind(trend_df, location_trends)
}

write_tsv(trend_df, "../data/interim/per_location_env_var_slopes.csv")
trend_df = as_tibble(trend_df)

#trend_df = read_tsv("../data/interim/per_location_env_var_slopes.csv")




################################################################################
################################################################################
################################################################################
##########
# Spot check the data
#########

print("switched outlier filtering to the scaled data")
#look at the scaled ones and throw the neceeary exclusions in here.
sub_trend_df = trend_df[trend_df$slope > -0.1,]
sub_trend_df = sub_trend_df[sub_trend_df$slope < 0.04,]

print("second outlier removal based on the scaled results")
print("looking at sever outliers, likely not due to real climactic differences")
print("more likely the result of some measurement or acquisition error")
hist(sub_trend_df[sub_trend_df$clim_var == "Atmospheric.Pressure",]$slope)
min(sub_trend_df[sub_trend_df$clim_var == "Atmospheric.Pressure",]$slope)
hist(sub_trend_df[sub_trend_df$clim_var == "Snow.Precipitation",]$slope)
max(sub_trend_df[sub_trend_df$clim_var == "Snow.Precipitation",]$slope)
hist(sub_trend_df[sub_trend_df$clim_var == "Snow.Depth.Accumulation",]$slope)
max(sub_trend_df[sub_trend_df$clim_var == "Snow.Depth.Accumulation",]$slope)
hist(sub_trend_df[sub_trend_df$clim_var == "Minimum.Air.Temperature",]$slope)
max(sub_trend_df[sub_trend_df$clim_var == "Minimum.Air.Temperature",]$slope)




trendline_boxplots =  ggplot(data = sub_trend_df, aes(x = clim_var, y = slope)) + 
  geom_boxplot()+
  labs(title = "variation in environmental variable slopes across locations",
       subtitle = "dropped outliers of >0.02 and < 0.02 (2 points removed)")+
  xlab("climate variable") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylab("slope of time series trendline")

ggsave("../data/trendline_boxplots.png", trendline_boxplots)



sub_df
clim_var ="Air.Temperature"
time_val = "time_series_x"
location

plot_time_series = function(df, time_val, clim_var){
out =  ggplot(data = df, aes(x = .data[[time_val]], y = .data[[clim_var]])) + 
  geom_point()+
  geom_smooth(method=lm , color="red", se=TRUE) +
  labs(title = paste0("Time series plot for location: ", location ),
       subtitle = paste0("Response variable: ", clim_var ))+
  xlab("date series from Jan 1 1980") +
  ylab(clim_var) +
  theme_classic()
} 


eng_temp_plot = plot_time_series(sub_df, "time_series_x", "Air.Temperature")

ggsave("../data/example_slope_plot.png", eng_temp_plot)

eng_dir_plot = plot_time_series(sub_df, "time_series_x", "Wind.Direction")

ggsave("../data/example_slope_plot2.png", eng_dir_plot)

#figure out what is in there on a per location basis, then do some time series trendlines if
# there are per time data per location. generalize the functions to get the 
# per location deltas for the fetures.


################################################################################
################################################################################
################################################################################
######
# gather and summarieze the trends
# need to know what axes are associated with which slopes!
######

print("TODO - want to switch this to using sub_trend_df")
print("the outliers do seem weird")

#can then gather the trends to go from wide data to long.
#then do a dimensionality reduction on how things are changing
slope_df = sub_trend_df %>%
  select(clim_var, location, slope) %>%
  pivot_wider(names_from = clim_var, values_from = slope)

print("second outlier removal based on the scaled results and backtrack to histograms")

slope_df = slope_df[slope_df$Atmospheric.Pressure > 0.0,]
slope_df = slope_df[slope_df$Snow.Precipitation < 0.00015,]
slope_df = slope_df[slope_df$Snow.Depth.Accumulation < 0.004,]
slope_df = slope_df[slope_df$Minimum.Air.Temperature > -1e-04,]


sub_df = slope_df[names(slope_df) != "location"]

scaled_slope_df = as_tibble(scale(sub_df))
slope_df = cbind(slope_df["location"], scaled_slope_df)

print("drop atmospheric pressue due to zero variance")
slope_df = subset(slope_df, select = -c(Atmospheric.Pressure) )
slope_df = na.omit(slope_df)


long_scaled = slope_df %>%
  pivot_longer(
    cols = names(slope_df)[names(slope_df) != "location"],
    names_to = "clim_var",
    values_to = "slope",
    values_drop_na = TRUE
  )


scaled_trendline_boxplots =  ggplot(data = long_scaled, aes(x = clim_var, y = slope)) + 
  geom_boxplot()+
  labs(title = "variation in environmental variable slopes across locations",
       subtitle = "standard scaling of the slopes per-variable")+
  xlab("climate variable") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylab("scaled slope of time series trendline")

ggsave("../data/scaled_trendline_boxplots.png", scaled_trendline_boxplots)




slope_df = as_tibble(slope_df)

print("limit to locations with genetic data")
het_dat = read_tsv("../data/interim/per_location_heterozygosity_summary.tsv")
het_dat$location
slope_df = slope_df[slope_df$location %in% het_dat$location,]


################################################################################
################################################################################
################################################################################
print("run PCA on the remaining locations to assess if there is strcture to the data")
#135 locations remaining after the filtering

sub_climate_vars = c("Minimum.Air.Temperature", "Air.Temperature",        "Maximum.Air.Temperature", "Total.Precipitation",
                 "Dew.Point.Temperature",  "Relative.Humidity",     "Wind.Direction",        "Solar.Radiation",    
                  "Snow.Precipitation",      "Snow.Depth.Accumulation", "Snow.Water.Equivalent",
                 "Wind.Speed.at.2.meters") 



env_pca = PCA(slope_df[sub_climate_vars], scale.unit = TRUE, graph = FALSE)
print(env_pca)
summary(env_pca)

get_eigenvalue(env_pca)
# eigenvalue variance.percent cumulative.variance.percent
# Dim.1  3.617375e+00     3.014479e+01                    30.14479
# Dim.2  2.647961e+00     2.206634e+01                    52.21114
# Dim.3  1.548072e+00     1.290060e+01                    65.11174
# Dim.4  1.334337e+00     1.111947e+01                    76.23121
# Dim.5  1.086936e+00     9.057797e+00                    85.28901
# Dim.6  6.987789e-01     5.823158e+00                    91.11216
# Dim.7  5.413427e-01     4.511189e+00                    95.62335
# Dim.8  2.959287e-01     2.466073e+00                    98.08943
# Dim.9  1.550958e-01     1.292465e+00                    99.38189
# Dim.10 6.640724e-02     5.533937e-01                    99.93528
# Dim.11 7.760903e-03     6.467419e-02                    99.99996
# Dim.12 4.900778e-06     4.083981e-05                   100.00000
# Dim.13 1.609254e-33     1.341045e-32                   100.00000
get_pca_ind(env_pca)$coord

description_env_pca = dimdesc(env_pca, axes = c(1,2), proba = 0.01)
description_env_pca

env_pca_df = as_tibble(get_pca_ind(env_pca)$coord)
names(env_pca_df) = c("PC1", "PC2", "PC3","PC4", "PC5")

env_pca_df$location = slope_df$location

meta_sub_df = clustered_full_data_PCA[c("SiteCode", "Cluster", "lat", "lon")]
meta_sub_df = unique(meta_sub_df)
meta_sub_df$location = meta_sub_df$SiteCode

env_pca_df_w_meta = left_join(env_pca_df, meta_sub_df)

print("write to a file")
write_tsv(env_pca_df_w_meta, '../data/interim/PCs_of_environmental_slopes_with_meta.tsv')

per_location_pcs_env = ggplot() + geom_point(data = env_pca_df_w_meta, aes(x = PC1, y = PC2, colour=Cluster))+
  labs(title =  "Atlantic salmon sampling locations PCs of environmental variation", 
       subtitle = "Summary of scaled environmental regression coefficients for 1980 - 2022")+
  xlab("PC1, 30.1% variance explained") +
  ylab("PC2, 26.5% variance explained")

ggsave('../data/external/environmental_slope_PCA_by_location.png', per_location_pcs_env)


print("plot the PC values on a map")
# #Possibly:
world = ne_countries(scale = "medium", returnclass = "sf")
class(world)
# #plot a sub region
lat_min = min(meta_sub_df$lat, na.rm = TRUE)
lat_max = max(meta_sub_df$lat, na.rm = TRUE)
long_min = min(meta_sub_df$lon, na.rm = TRUE)
long_max = max(meta_sub_df$lon, na.rm = TRUE)
# 
theme_set(theme_bw())

pc1_env_variance_by_study_range = ggplot(data = world) +
   geom_sf() +
   coord_sf(xlim = c(long_min - 2, long_max + 2), 
            ylim = c(lat_min - 2, lat_max + 2), expand = FALSE) +
   labs(title = "Salmon sampling locations", 
        subtitle = "coloured by PC1 of environmental slope")+
   geom_jitter(data = env_pca_df_w_meta, aes(x = lon, y = lat, colour=PC1))

ggsave('../data/external/PC1_environmental_slope_variation.png', pc1_env_variance_by_study_range)

pc2_env_variance_by_study_range = ggplot(data = world) +
  geom_sf() +
  coord_sf(xlim = c(long_min - 2, long_max + 2), 
           ylim = c(lat_min - 2, lat_max + 2), expand = FALSE) +
  labs(title = "Salmon sampling locations", 
       subtitle = "coloured by PC2 of environmental slope")+
    geom_jitter(data = env_pca_df_w_meta, aes(x = lon, y = lat, colour=PC2))
       
ggsave('../data/external/PC2_environmental_slope_variation.png', pc2_env_variance_by_study_range)

#PC1 big change in placentia bay region, PC2 locations are scattered, with north seeming high






################################################################################
################################################################################
################################################################################

print("load the heterozygosity per location")


print("TODO - sub in a different response variable, look at the per location effective population size")
#either with:
#  http://www.molecularfisherieslaboratory.com.au/neestimator-software/
#or:
#  https://www.frontiersin.org/articles/10.3389/fgene.2015.00109/full


het_dat = read_tsv("../data/interim/per_location_heterozygosity_summary.tsv")
#drop low sample size locations
het_dat = het_dat[het_dat$n_individuals > 10,]
table(het_dat$n_individuals)

print("assess varability of heterozygosity per location")
hist(het_dat$n_individuals)
hist(het_dat$mean_obvs_het) #normally distributed
hist(het_dat$mean_expe_het) #normally distributed

print("plot heterozygosity as heatmap on locations (+with the admixture)")


print("join the heterozygosity information with the environmental info")
print("TODO - need to go through slope_df and vet any outliers via spot check plots as per above.")

het_and_env = left_join(het_dat, slope_df)

print("drop the unmatched rows")
sum(is.na(het_and_env))

het_and_env = na.omit(het_and_env)
#132 complete cases of the sample size and environmental data after outliers of both removed


het_and_env = left_join(het_and_env, env_pca_df_w_meta)
het_and_env = na.omit(het_and_env)


print("determine correlations of the r2 per location")

het_and_env #use the scaled version of the slopes
het_and_env = as_tibble(het_and_env)

df = het_and_env
predictor = "Total.Precipitation"
predictor = "Air.Temperature"
response = "mean_obvs_het"


# [1] "location"                "n_individuals"           "mean_obvs_het"           "mean_expe_het"          
# [5] "n_loci"                  "n_fdr_sig"               "Minimum.Air.Temperature" "Air.Temperature"        
# [9] "Maximum.Air.Temperature" "Total.Precipitation"     "Dew.Point.Temperature"   "Relative.Humidity"      
# [13] "Wind.Direction"          "Solar.Radiation"         "Atmospheric.Pressure"    "Snow.Precipitation"     
# [17] "Snow.Depth.Accumulation" "Snow.Water.Equivalent"   "Wind.Speed.at.2.meters" 
df = df[df$Air.Temperature < 0.0002,]
out =  ggplot(data = df, aes(x = .data[[predictor]], y = .data[[response]], colour = Cluster)) + 
  geom_point()+
  geom_smooth(method=lm , color="red", se=TRUE) +
  labs(title =  "Example plot of slope vs genetics. See Lab getting hotter, few locations with low heterozygosity",
       subtitle = paste0("Predictor variable: ", predictor ))+
  xlab(paste0("slope of ", predictor, " trendline since 1980")) +
  ylab(response) +
  theme_classic()



print("linear model of the uncorrelated predictors r2 + the average heterozygosity per location ")

model_of_heterozygosity = lm(mean_obvs_het~Minimum.Air.Temperature+Air.Temperature+Maximum.Air.Temperature+Total.Precipitation+
                               Dew.Point.Temperature+Relative.Humidity+Wind.Direction+Solar.Radiation+
                               Snow.Precipitation+Snow.Depth.Accumulation+Snow.Water.Equivalent+Wind.Speed.at.2.meters,
                             het_and_env)

summary(model_of_heterozygosity)

# sig coefs for - "Total.Precipitation", "Relative.Humitidy", "Wind.Speed.at.2.meters", 


#the associations with the response are not significant, therefore the present heterozygosity
#is not dependent on the differences in climate variables.

#not necessarily a measure of significance we're after though. want the outliers from an insignificant trendline
# i.e. where is there low heterozygosity and big change in environment?

#consider above in conjuction with the heterozygosity vs. the PCs


PC_model_of_heterozygosity = lm(mean_obvs_het~PC1+PC2, het_and_env)
summary(PC_model_of_heterozygosity)

PC1_model_of_heterozygosity = lm(mean_obvs_het~PC1, het_and_env)
summary(PC1_model_of_heterozygosity)

PC2_model_of_heterozygosity = lm(mean_obvs_het~PC2, het_and_env)
summary(PC2_model_of_heterozygosity)


# Can still do:
##    - outlier pairs to ID danger zones: high or low slope locations, 
##      and low heterozygosity (bad) and high heterozygosity (good)
##    - do the same locations keep popping up in the outlier bins? these would be where
##      the populations are most at risk due to climate change



# vizualize a multiple regression:
# https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html

#or facet the scatter plots, same response vs. the different preidctors




print("TODO - clean this up!")
print("make a separate folder and split into more digestable scripts")


print("effective population size estimates are proving inaccurate/unreliable (infinite ne in some cases)")
print("therefore will remain with average heterozygosity as the response for now")