setwd("../data/")

library(tidyverse)
library(psych)    # Used to investigate correlations among predictors
library(vegan)    # Used to run RDA
#library(ggman)

print("read in the full data set")
snp_data = read_tsv("interim/RDA_input_uncor_env_and_5k_random_subset_Genetics_v2.tsv")


snp_data = snp_data[snp_data$FID != "Mul",]

names(snp_data)

print("low missing data numbers")
#sapply(snp_data, function(x) sum(is.na(x)))
print("fill with zeros")
snp_data[is.na(snp_data)] = 0

id_cols = names(snp_data)[1:2]
env_cols = names(snp_data)[3:8]
gen_cols = names(snp_data)[9:length(names(snp_data))]

print("Read in the metadata, associate the relevant cols with the matricies above")

env_data = read_tsv("full_wild_PCA_and_meta.tsv")
#
env_data = env_data[env_data$fish_id %in% snp_data$IID,]
env_data$IID = env_data$fish_id


corr_vars = c( 'lat', 'lon')
env_cols = c(env_cols, corr_vars)
print("Run the RDA")

# take the associated data and make the x and y matricies
#y = snp_data[gen_cols]
#X = snp_data[env_cols]

#dim(y) #
#dim(X) #

#env_data_pos
fst_env_latlong_input = left_join(snp_data, env_data[c('IID', 'lat', 'lon')])

fst_env_latlong_input = fst_env_latlong_input[!is.na(fst_env_latlong_input$lat),]

#######################
# run the RDA
#######################
# run the RDA
#full_snp_latlong_rda_out = rda(y~., data = X, scale=T) #thats a terrible function call

 
#USING a Lat/Long spatial correction
full_snp_latlong_rda_out = rda(fst_env_latlong_input[gen_cols] ~ Wind.Direction + Snow.Precipitation + Wind.Speed.at.2.meters +
                        Solar.Radiation + Total.Precipitation + Air.Temperature + 
                        Condition(lat + lon),
                      data = fst_env_latlong_input[env_cols], 
                      scale=T) #that is an even more terrible function call



## Save an object to a file
#save.image(file = "rda_5k_LatLong_snp_data.rds")
## Restore the object
# load(file = "rda_5k_data.rds")



print("analyze the RDA outputs")

RsquareAdj(full_snp_latlong_rda_out)
# $r.squared
# [1] 0.0131464
# 
# $adj.r.squared
# [1] 0.01161054

print("had 3k RDA axes, and the r2 of one, looks like it ran to complete decomposition")
summ_info = summary(eigenvals(full_snp_latlong_rda_out, model = "constrained"))
# 
# Importance of components:
#   RDA1    RDA2    RDA3   RDA4   RDA5    RDA6
# Eigenvalue            20.2985 12.6562 10.5852 9.0734 7.3166 5.80207
# Proportion Explained   0.3088  0.1925  0.1610 0.1380 0.1113 0.08827
# Cumulative Proportion  0.3088  0.5013  0.6624 0.8004 0.9117 1.00000

summ_df = as_tibble(t(data.frame(summ_info)))
summ_df$RDA_axis = unlist(lapply(1:nrow(summ_df), function(x){paste0("RDA_", x)}))
dim(summ_df)
write_tsv(summ_df, "5k_snp_LatLong_RDA_axes_summary.tsv")

screeplot(full_snp_latlong_rda_out) 
print("first axes explains higher proportion then drop off")

print("add the meta data columns for plotting by colour")
NA_PC_Meta = read_tsv("full_wild_PCA_and_meta.tsv")
#add province data to the original meta data file, for consistency
prov_dict = distinct(NA_PC_Meta[c("Province", "SiteCode")])
prov_ids = prov_dict$Province
names(prov_ids) = prov_dict$SiteCode

meta_data = read_tsv('raw/Salmo_220K_Merged2022_ENVmatchyear_Metadata.txt')      
#meta_data = read_tsv('Salmo_220K_Merged2022_ENVmatchyear_Metadata.txt')      
meta_data$province = unlist(lapply(meta_data$SiteCode, function(x){prov_ids[[x]]}))

print("join the metadata to the correct order of the fish in the RDA")
NA_PC_Meta$IID = NA_PC_Meta$fish_id
sub_meta_for_match = left_join(data.frame(IID = snp_data$IID), NA_PC_Meta)

unique(sub_meta_for_match$Province)
sub_meta_for_match[is.na(sub_meta_for_match$Province),]

summary(full_snp_latlong_rda_out)

plot(full_snp_latlong_rda_out, scaling=3) 

prov = sub_meta_for_match$Province

is.na(prov) = "NA" 

print("make the provincial colours for plot")
province_vals = c("NL-Labrador", "QC", "NB", "PEI", "NS", "NL", "NA") 
prov_colours = c("#0063a3",   "#fbad26", "#252a2e", "#b44e2a", "#349c44", "#c678dd", "#FFFFFF")
names(prov_colours) = province_vals

pdf("5k_rda_LatLong_plot.pdf")

plot(full_snp_latlong_rda_out, type="n", scaling=3)
points(full_snp_latlong_rda_out, display="species", pch=20, cex=0.7, col="gray32", scaling=3)  #snps
points(full_snp_latlong_rda_out, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=prov_colours[prov]) #individuals coloured by cluster
text(full_snp_latlong_rda_out, scaling=3, display="bp", col="#0868ac", cex=1)               # the env
legend("bottomright", legend=names(prov_colours), bty="n", col="gray32", pch=21, cex=1, pt.bg=prov_colours)

# Closing the graphical device
dev.off() 

pdf("no_env_5k_rda_LatLong_plot.pdf")

plot(full_snp_latlong_rda_out, type="n", scaling=3)
points(full_snp_latlong_rda_out, display="species", pch=20, cex=0.7, col="gray32", scaling=3)  #snps
points(full_snp_latlong_rda_out, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=prov_colours[prov]) #individuals coloured by cluster
legend("bottomright", legend=names(prov_colours), bty="n", col="gray32", pch=21, cex=1, pt.bg=prov_colours)

# Closing the graphical device
dev.off() 


load_rda = scores(full_snp_latlong_rda_out, choices=c(1:3), display="species")  # Species scores for the first three constrained axes
hist(load_rda[,1], main="Loadings on RDA1") #this one is a little off the normal distribution
hist(load_rda[,2], main="Loadings on RDA2")



print("extract the RDA1 loadings and do a manhattan plot")

sum_dat = summary(full_snp_latlong_rda_out) 
loadings = as_tibble(data.frame(loadings = sum_dat$species))
loadings$raw_marker = rownames(sum_dat$species)
loadings$marker = unlist(lapply(loadings$raw_marker, function(x){strsplit(x, "_")[[1]][[1]]}))
print("then get the map file loaded in to subset the positions")

map_file = "Salmo_220K_Merged2022_COMPLETE_ENVmatchyear.map"
#map_file = "raw/Salmo_220K_Merged2022_COMPLETE_ENVmatchyear.map"
map_df = read_tsv(map_file, skip = 0, col_names = c("chromosome", "marker" , "genetic_distance", "physical_distance"))



loadings_man_df = left_join(loadings, map_df)


plot1 = ggman(loadings_man_df, snp = "marker", bp = "genetic_distance", chrom = "chromosome", pvalue = "loadings.RDA1")+
  labs(title =  "RDA1 loadings for the 5k random SNP subset RDA")+
  xlab("Chromosome") +
  ylab("RDA1 loading value")+
  theme_minimal()

ggsave(paste0('external/RDA1_loadings_5k_snp_LatLong.png'), plot1,  width = 8, height = 3)

plot2 = ggman(loadings_man_df, snp = "marker", bp = "genetic_distance", chrom = "chromosome", pvalue = "loadings.RDA2", logTransform = TRUE)+
  labs(title =  "RDA2 loadings for the 5k random SNP subset RDA")+
  xlab("Chromosome") +
  ylab("RDA2 value")+
  theme_minimal()


ggsave(paste0('external/RDA2_loadings_5k_snp_LatLong.png'), plot2,  width = 8, height = 3)


outlier_snps_from_rda_loadings = function(x,z = 3){
  lims <- mean(x) + c(-1, 1) * z * sd(x)     # find loadings +/-z sd from mean loading     
  x[x < lims[1] | x > lims[2]]               # locus names in these tails
}


axis_1_candidates = outlier_snps_from_rda_loadings(load_rda[,1],3) # 18
axis_1_cand_df = loadings_man_df[loadings_man_df$raw_marker %in% names(axis_1_candidates),]
table(axis_1_cand_df$chromosome)
print("cluster on chr23 when there is the correction for lat/long")
# 1  4  5  6  7  9 10 11 13 15 17 19 20 21 23 25 26 28 29 
# 9  3  2  1  1  3  2  1  6  1  2  1  2  1 18  2  1  1  1 

axis_2_candidates = outlier_snps_from_rda_loadings(load_rda[,2],3) # 37
axis_2_cand_df = loadings_man_df[loadings_man_df$raw_marker %in% names(axis_2_candidates),]
table(axis_2_cand_df$chromosome)

# 1  2  3  4  5  7  8  9 10 11 12 13 14 15 20 21 22 23 25 26 
# 2  1  1  2  1  1  1  2  1  1  2  5  3  4  1  2  1  2  1  2 

## Save an object to a file
save.image(file = "rda_5k_snp_data_LatLong_final.rds")
# load(file = "rda_full_snp_data_final.rds")
