
# See notes on:
# New method to quantify climactic differences
# Go through the plan there, looking at if all the requesite data are available, if
# so then set up a subfolder here and get to work on generating the data and 
# using it to conduct the analyses.

#######
# location
####### 
setwd("C:/Users/camnu/bin/salmon-genomic-vulnerability/scripts")

#######
# libraries
####### 

library(tidyverse)
library(FactoMineR)
library(factoextra)

#######
# functions
####### 


#######
# genetic response variable
####### 

print("stand in for the final response variable")
print("would want the per location mean heterozygosity I think")
print("would this be effected by sammple size?")

clustered_full_data_PCA = read_tsv( "../data/interim/full_data_PCA_kmeans_cluster_info.tsv")
climate_vars = c("Minimum.Air.Temperature", "Air.Temperature",        "Maximum.Air.Temperature", "Total.Precipitation",
                 "Dew.Point.Temperature",  "Relative.Humidity",     "Wind.Direction",        "Solar.Radiation",    
                 "Atmospheric.Pressure",  "Snow.Precipitation",      "Snow.Depth.Accumulation", "Snow.Water.Equivalent",
                 "Wind.Speed.at.2.meters") 



################################################################################
################################################################################
################################################################################
#######
# per location trend calculations
####### 

diff_days = function(year, month, day, baseline = "1979-12-31"){
  as.numeric(difftime(paste0(year, "-", month,"-", day), baseline , units = "days"))
}

## This was run, can start with the saved version to save time.
#climate_df = read_csv("../data/raw/ClimateDataSalmon_1980_2022.csv")
#climate_df$time_series_x = unlist(lapply(1:nrow(climate_df), function(i){
#  diff_days(climate_df$Year[[i]], climate_df$Month[[i]], climate_df$Day[[i]])
#}))
#write_csv(climate_df, "../data/raw/MODDED_ClimateDataSalmon_1980_2022.csv")

climate_df = read_csv("../data/raw/MODDED_ClimateDataSalmon_1980_2022.csv")


trend_df = data.frame()

#location = "ENG"
for (location in unique(climate_df$Name)){
  print(paste0("on location: ", location))
  #has the per day info for 1980 - 2022
  sub_df = climate_df[climate_df$Name == location,]
  
  location_trends = data.frame()
  #clim_var = "Air.Temperature"
  for(clim_var in climate_vars){
    print(paste0("on variable: ", clim_var))
    #put the given variable into the formula
    assoc_test = lm(as.formula(paste0(clim_var, "~time_series_x")), sub_df)
    
    intercept = assoc_test$coefficients[[2]]
    slope = assoc_test$coefficients[[2]]
    
    trends = data.frame(clim_var = clim_var, intercept = intercept, slope = slope)
    location_trends = rbind(location_trends, trends)
  }
  location_trends$location = location
  
  trend_df = rbind(trend_df, location_trends)
}

write_tsv(trend_df, "../data/interim/per_location_env_var_slopes.csv")
trend_df = as_tibble(trend_df)

#trend_df = read_tsv("../data/interim/per_location_env_var_slopes.csv")




################################################################################
################################################################################
################################################################################
##########
# Spot check the data
#########

print("switched outlier filtering to the scaled data")
#look at the scaled ones and throw the neceeary exclusions in here.
sub_trend_df = trend_df



trendline_boxplots =  ggplot(data = sub_trend_df, aes(x = clim_var, y = slope)) + 
  geom_boxplot()+
  labs(title = "variation in environmental variable slopes across locations",
       subtitle = "dropped outliers of >0.02 and < 0.02 (2 points removed)")+
  xlab("climate variable") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylab("slope of time series trendline")

ggsave("../data/trendline_boxplots.png", trendline_boxplots)



sub_df
clim_var ="Air.Temperature"
time_val = "time_series_x"
location

plot_time_series = function(df, time_val, clim_var){
out =  ggplot(data = df, aes(x = .data[[time_val]], y = .data[[clim_var]])) + 
  geom_point()+
  geom_smooth(method=lm , color="red", se=TRUE) +
  labs(title = paste0("Time series plot for location: ", location ),
       subtitle = paste0("Response variable: ", clim_var ))+
  xlab("date series from Jan 1 1980") +
  ylab(clim_var) +
  theme_classic()
} 


eng_temp_plot = plot_time_series(sub_df, "time_series_x", "Air.Temperature")

ggsave("../data/example_slope_plot.png", eng_temp_plot)

eng_dir_plot = plot_time_series(sub_df, "time_series_x", "Wind.Direction")

ggsave("../data/example_slope_plot2.png", eng_dir_plot)

#figure out what is in there on a per location basis, then do some time series trendlines if
# there are per time data per location. generalize the functions to get the 
# per location deltas for the fetures.


################################################################################
################################################################################
################################################################################
######
# gather and summarieze the trends
# need to know what axes are associated with which slopes!
######

print("TODO - want to switch this to using sub_trend_df")
print("the outliers do seem weird")

#can then gather the trends to go from wide data to long.
#then do a dimensionality reduction on how things are changing
slope_df = sub_trend_df %>%
  select(clim_var, location, slope) %>%
  pivot_wider(names_from = clim_var, values_from = slope)

sub_df = slope_df[names(slope_df) != "location"]

scaled_slope_df = as_tibble(scale(sub_df))
slope_df = cbind(slope_df["location"], scaled_slope_df)

long_scaled = slope_df %>%
  pivot_longer(
    cols = names(slope_df)[names(slope_df) != "location"],
    names_to = "clim_var",
    values_to = "slope",
    values_drop_na = TRUE
  )



scaled_trendline_boxplots =  ggplot(data = long_scaled, aes(x = clim_var, y = slope)) + 
  geom_boxplot()+
  labs(title = "variation in environmental variable slopes across locations",
       subtitle = "standard scaling of the slopes per-variable")+
  xlab("climate variable") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ylab("scaled slope of time series trendline")

ggsave("../data/scaled_trendline_boxplots.png", scaled_trendline_boxplots)


print("second outlier removal based on the scaled results")

slope_df = slope_df[slope_df$Atmospheric.Pressure > -5,]
slope_df = slope_df[slope_df$Snow.Precipitation < 7.5,]
slope_df = slope_df[slope_df$Snow.Depth.Accumulation < 7.5,]

slope_df = as_tibble(slope_df)

print("limit to locations with genetic data")
het_dat = read_tsv("../data/interim/per_location_heterozygosity_summary.tsv")
het_dat$location
slope_df = slope_df[slope_df$location %in% het_dat$location,]


################################################################################
################################################################################
################################################################################
print("run PCA on the remaining locations to assess if there is strcture to the data")
#136 locations remaining after the filtering




env_pca = PCA(slope_df[climate_vars], scale.unit = TRUE, graph = FALSE)
print(env_pca)
summary(env_pca)

get_eigenvalue(env_pca)
# eigenvalue variance.percent cumulative.variance.percent
# Dim.1  4.023447e+00     3.094960e+01                    30.94960
# Dim.2  2.368994e+00     1.822303e+01                    49.17263
# Dim.3  1.413386e+00     1.087220e+01                    60.04483
# Dim.4  1.315873e+00     1.012210e+01                    70.16693
# Dim.5  1.077559e+00     8.288912e+00                    78.45584
# Dim.6  1.000000e+00     7.692308e+00                    86.14815
# Dim.7  7.150286e-01     5.500220e+00                    91.64837
# Dim.8  5.370706e-01     4.131312e+00                    95.77968
# Dim.9  3.186359e-01     2.451045e+00                    98.23073
# Dim.10 1.481839e-01     1.139876e+00                    99.37060
# Dim.11 7.461381e-02     5.739524e-01                    99.94455
# Dim.12 7.204526e-03     5.541943e-02                    99.99997
# Dim.13 3.374282e-06     2.595602e-05                   100.00000
get_pca_ind(env_pca)$coord

description_env_pca = dimdesc(env_pca, axes = c(1,2), proba = 0.01)
description_env_pca

env_pca_df = as_tibble(get_pca_ind(env_pca)$coord)
names(env_pca_df) = c("PC1", "PC2", "PC3","PC4", "PC5")

env_pca_df$location = slope_df$location

meta_sub_df = clustered_full_data_PCA[c("SiteCode", "Cluster", "lat", "lon")]
meta_sub_df = unique(meta_sub_df)
meta_sub_df$location = meta_sub_df$SiteCode

env_pca_df_w_meta = left_join(env_pca_df, meta_sub_df)

print("write to a file")
write_tsv(env_pca_df_w_meta, '../data/interim/PCs_of_environmental_slopes_with_meta.tsv')

per_location_pcs_env = ggplot() + geom_point(data = env_pca_df_w_meta, aes(x = PC1, y = PC2, colour=Cluster))+
  labs(title =  "Atlantic salmon sampling locations PCs of environmental variation", 
       subtitle = "Summary of scaled environmental regression coefficients for 1980 - 2022")+
  xlab("PC1, 30.9% variance explained") +
  ylab("PC2, 18.2% variance explained")

ggsave('../data/external/environmental_slope_PCA_by_location.png', per_location_pcs_env)

# #Possibly:
# #plot the PCs on the heatmap
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
world = ne_countries(scale = "medium", returnclass = "sf")
class(world)
# #plot a sub region
lat_min = min(meta_sub_df$lat, na.rm = TRUE)
lat_max = max(meta_sub_df$lat, na.rm = TRUE)
long_min = min(meta_sub_df$lon, na.rm = TRUE)
long_max = max(meta_sub_df$lon, na.rm = TRUE)
# 
theme_set(theme_bw())

pc1_env_variance_by_study_range = ggplot(data = world) +
   geom_sf() +
   coord_sf(xlim = c(long_min - 2, long_max + 2), 
            ylim = c(lat_min - 2, lat_max + 2), expand = FALSE) +
   labs(title = "Salmon sampling locations", 
        subtitle = "coloured by PC1 of environmental slope")+
   geom_jitter(data = env_pca_df_w_meta, aes(x = lon, y = lat, colour=PC1))

ggsave('../data/external/PC1_environmental_slope_variation.png', clusters_by_study_range)

pc2_env_variance_by_study_range = ggplot(data = world) +
  geom_sf() +
  coord_sf(xlim = c(long_min - 2, long_max + 2), 
           ylim = c(lat_min - 2, lat_max + 2), expand = FALSE) +
  labs(title = "Salmon sampling locations", 
       subtitle = "coloured by PC2 of environmental slope")+
    geom_jitter(data = env_pca_df_w_meta, aes(x = lon, y = lat, colour=PC2))
       
ggsave('../data/external/PC2_environmental_slope_variation.png', pc2_env_variance_by_study_range)








################################################################################
################################################################################
################################################################################

print("load the heterozygosity per location")


print("TODO - sub in a different response variable, look at the per location effective population size")
#either with:
#  http://www.molecularfisherieslaboratory.com.au/neestimator-software/
#or:
#  https://www.frontiersin.org/articles/10.3389/fgene.2015.00109/full


het_dat = read_tsv("../data/interim/per_location_heterozygosity_summary.tsv")
#drop low sample size locations
het_dat = het_dat[het_dat$n_individuals > 10,]
table(het_dat$n_individuals)

print("assess varability of heterozygosity per location")
hist(het_dat$n_individuals)
hist(het_dat$mean_obvs_het) #normally distributed
hist(het_dat$mean_expe_het) #normally distributed

print("plot heterozygosity as heatmap on locations (+with the admixture)")


print("join the heterozygosity information with the environmental info")
print("TODO - need to go through slope_df and vet any outliers via spot check plots as per above.")

het_and_env = left_join(het_dat, slope_df)

print("drop the unmatched rows")
sum(is.na(het_and_env))

het_and_env = na.omit(het_and_env)
#132 complete cases of the sample size and environmental data after outliers of both removed

print("determine correlations of the r2 per location")

het_and_env #use the scaled version of the slopes
het_and_env = as_tibble(het_and_env)

df = het_and_env
predictor = "Total.Precipitation"
response = "mean_obvs_het"


# [1] "location"                "n_individuals"           "mean_obvs_het"           "mean_expe_het"          
# [5] "n_loci"                  "n_fdr_sig"               "Minimum.Air.Temperature" "Air.Temperature"        
# [9] "Maximum.Air.Temperature" "Total.Precipitation"     "Dew.Point.Temperature"   "Relative.Humidity"      
# [13] "Wind.Direction"          "Solar.Radiation"         "Atmospheric.Pressure"    "Snow.Precipitation"     
# [17] "Snow.Depth.Accumulation" "Snow.Water.Equivalent"   "Wind.Speed.at.2.meters" 

out =  ggplot(data = df, aes(x = .data[[predictor]], y = .data[[response]])) + 
  geom_point()+
  geom_smooth(method=lm , color="red", se=TRUE) +
  labs(title =  "",
       subtitle = paste0("Predictor variable: ", predictor ))+
  xlab(paste0("slope of ", predictor, " trendline since 1980")) +
  ylab(response) +
  theme_classic()




print("linear model of the uncorrelated predictors r2 + the average heterozygosity per location ")

model_of_heterozygosity = lm(mean_obvs_het~Minimum.Air.Temperature+Air.Temperature+Maximum.Air.Temperature+Total.Precipitation+
                               Dew.Point.Temperature+Relative.Humidity+Wind.Direction+Solar.Radiation+Atmospheric.Pressure+
                               Snow.Precipitation+Snow.Depth.Accumulation+Snow.Water.Equivalent+Wind.Speed.at.2.meters,
                             het_and_env)

summary(model_of_heterozygosity)

# sig coefs for - "Total.Precipitation", 


#the associations with the response are not significant, therefore the present heterozygosity
#is not dependent on the differences in climate variables.

# Can still do:
##    - outlier pairs to ID danger zones: high or low slope locations, 
##      and low heterozygosity (bad) and high heterozygosity (good)
##    - do the same locations keep popping up in the outlier bins? these would be where
##      the populations are most at risk due to climate change



# vizualize a multiple regression:
# https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html

#or facet the scatter plots, same response vs. the different preidctors


print("TODO - possible improvement: change the slopes to all positive values before applying a standard scaler")
print("that way not making any assumptions about a positive or negative change being more important, have change itslef as the prediction")
print("this will make it a possion distribution I think, so will need to make sure the standard scaler can be applied in the same fashion")