library
install.packages('tidyverse')
install.packages('coil')
install.packages('aphid')
library("aphid")
states <- c("Begin", "Fair", "Loaded")
residues <- paste(1:6)
### Define transition probability matrix A
A <- matrix(c(0, 0, 0, 0.99, 0.95, 0.1, 0.01, 0.05, 0.9), nrow = 3)
dimnames(A) <- list(from = states, to = states)
### Define emission probability matrix E
E <- matrix(c(rep(1/6, 6), rep(1/10, 5), 1/2), nrow = 2, byrow = TRUE)
dimnames(E) <- list(states = states[-1], residues = residues)
### Create the HMM object
x <- structure(list(A = A, E = E), class = "HMM")
states
residues
data(casino)
### The actual path is stored in the names attribute of the sequence
actual <- c("F", "L")[match(names(casino), c("Fair", "Loaded"))]
### Find the predicted path
vit1 <- Viterbi(x, casino)
predicted <- c("F", "L")[vit1$path + 1]
predicted
casino.post <- posterior(x, casino)
plot(1:300, seq(0, 1, length.out = 300), type = "n", xlab = "Roll number",
ylab = "Posterior probability of dice being fair")
starts <- which(c("L", actual) == "F" & c(actual, "F") == "L")
ends <- which(c("F", actual) == "L" & c(actual, "L") == "F") - 1
for(i in 1:6) rect(starts[i], 0, ends[i], 1, col = "grey", border = NA)
lines(1:300, casino.post[1, ])
x
casino
installed.packages('motus')
installed.package('motus')
installed.packages('motus')
install.packages("remotes")
install_github("MotusWTS/motus")
library(remotes)
install_github("MotusWTS/motus")
#install.packages("ggmap")
library(ggmap)
library(motus)
# we must install and load other packages we will be using to manipulate and visualize these data
#install.packages("maps")
library(maps)
?motus
# we must install and load other packages we will be using to manipulate and visualize these data
#install.packages("maps")
library(maps)
#install.packages("tidyverse")
library(tidyverse)
#install.packages("rworldmap")
library(rworldmap)
#install.packages("ggmap")
library(ggmap)
library(motus)
library(lubridate)
# Set the system environment time zone to Greenwich Mean Time (UTC), to ensure that you are always working in UTC. This should be part of every working session.
Sys.setenv(TZ = "UTC")
# Lets start by determining what our working directory is so we know where our file will be saved.
getwd()
setwd("C:/Users/camnu/Desktop")
setwd("C:/Users/camnu/")
# Lets start by determining what our working directory is so we know where our file will be saved.
getwd()
setwd("C:/Users/camnu/Documents/")
# Lets start by determining what our working directory is so we know where our file will be saved.
getwd()
# receivers: "SG-4940RPI33FB7" (Sexton Site), "SG-B17ERPI36118" (Jiggens Bluff), "SG-9E7GRPI37554	" Plum Lake West
# download receiver data for one of the receivers
proj.num <- "SG-4940RPI33FB7"
# As you or other users upload data to our server, you may have additional tag detections that weren't present in your initial data download. Since the .motus file is a SQLite database, you can update your existing file with any newly available data, rather than doing a complete new download of the entire database. To open and update a detections database that already exists (has been downloaded previously), we use the tagme() function but set new = FALSE:
sql.motus <- tagme(projRecv = proj.num, new = FALSE, update = TRUE, dir = "./")
# To check if new data are available for your project or receiver without downloading the data, you can use the tellme() function
tellme(projRecv = proj.num)
#If you are working offline, and simply want to open an already downloaded database without connecting to the server to update, use new = FALSE and update = FALSE:
sql.motus <- tagme(projRecv = proj.num, new = FALSE, update = FALSE)
library(dplyr) # load dplyr package to use "tbl" function below
# this retrieves the "alltags" table from the "sql.motus" SQLite file we read in earlier
tbl.alltags <- tbl(sql.motus, "alltags") # virtual table
# receivers: "SG-4940RPI33FB7" (Sexton Site), "SG-B17ERPI36118" (Jiggens Bluff), "SG-9E7GRPI37554	" Plum Lake West
# download receiver data for one of the receivers
proj.num <- "SG-4940RPI33FB7"
sql.motus <- tagme(projRecv = proj.num, new = TRUE, update = TRUE)
sql.motus <- tagme(projRecv = proj.num, new = TRUE, update = TRUE)
sql.motus <- tagme(projRecv = proj.num, new = TRUE, update = TRUE)
# receivers: "SG-4940RPI33FB7" (Sexton Site), "SG-B17ERPI36118" (Jiggens Bluff), "SG-9E7GRPI37554	" Plum Lake West
# download receiver data for one of the receivers
proj.num <- "SG-4940RPI33FB7"
sql.motus <- tagme(projRecv = proj.num, new = TRUE, update = TRUE)
install.packages("tidyverse")
library(tidyverse)
library(data.table)
library(FactoMineR)
library(factoextra)
library(tidyverse)
library(data.table)
library(FactoMineR)
library(factoextra)
install.packages(c("ade4", "adegenet", "adespatial", "BiocManager", "blob", "brew", "broom", "bslib", "callr", "car", "caret", "classInt", "cli", "clipr", "colorspace", "commonmark", "conquer", "crayon", "DBI", "dbplyr", "dendextend", "desc", "devtools", "dplyr", "DT", "dtplyr", "e1071", "ellipse", "evaluate", "fansi", "farver", "fontawesome", "forcats", "foreach", "formatR", "future", "future.apply", "generics", "gert", "ggforce", "ggplot2", "globals", "glue", "googlesheets4", "gower", "GPArotation", "gtools", "haven", "hms", "htmltools", "httr", "igraph", "ipred", "iterators", "jsonlite", "knitr", "latticeExtra", "lavaan", "lme4", "magrittr", "maptools", "matrixStats", "mnormt", "modelr", "nloptr", "openssl", "packrat", "parallelly", "pkgload", "plyr", "polynom", "processx", "progressr", "proxy", "ps", "psychTools", "quantreg", "randomForest", "raster", "Rcpp", "RcppArmadillo", "RcppCNPy", "RcppEigen", "RCurl", "readr", "readxl", "recipes", "reprex", "reshape", "restfulr", "rlang", "rmarkdown", "RNeXML", "roxygen2", "rprojroot", "rsconnect", "RSQLite", "rstudioapi", "rvest", "s2", "sass", "segmented", "seqinr", "sf", "shiny", "skimr", "sp", "spdep", "stringi", "stringr", "terra", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "timeDate", "tinytex", "tweenr", "tzdb", "units", "usethis", "uuid", "vctrs", "vegan", "waldo", "xfun", "XML", "yaml"))
library(tidyverse)
install.packages("scales")
install.packages("scales")
library(tidyverse)
library(data.table)
install.packages('tidyverse')
library(tidyverse)
restart()
library(tidyverse)
library(data.table)
library(FactoMineR)
library(factoextra)
full_metadata = read_tsv("interim/salmo_220K_wildNA_ENVmatchyear_full_Metadata.tsv")
library(tidyverse)
remove.packages("rlang")
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
library(tidyverse)
install.packages("rlang")
remove.packages("tidyverse")
install.packages('tidyverse')
remove.packages("rlang")
remove.packages("tidyverse")
install.packages('tidyverse')
library(tidyverse)
library(tidyverse)
library(data.table)
library(FactoMineR)
install.packages("dplyr"
)
library(tidyverse)
library(data.table)
library(tidyverse)
install.packages("installr")
library(installr)
updateR()
updateR()
library(tidyverse)
print("extract just the significant locations from the data")
#######
# location
#######
setwd("C:/Users/camnu/bin/salmon-genomic-vulnerability/scripts")
library(tidyverse)
print("stand in for the final response variable")
print("would want the per location mean heterozygosity I think")
print("would this be effected by sammple size?")
trend_df = read_tsv("../data/interim/per_location_env_var_slopes.csv")
trend_df = as_tibble(trend_df)
outliers_a = trend_df[trend_df$slope < -0.02,]
outliers_b = trend_df[trend_df$slope > 0.02,]
sub_trend_df = trend_df[trend_df$slope > -0.1,]
sub_trend_df = sub_trend_df[sub_trend_df$slope < 0.1,]
sub_trend_df = trend_df[trend_df$slope > -0.02,]
sub_trend_df = sub_trend_df[sub_trend_df$slope < 0.02,]
#can then gather the trends to go from wide data to long.
#then do a dimensionality reduction on how things are changing
slope_df = sub_trend_df %>%
select(clim_var, location, slope) %>%
pivot_wider(names_from = clim_var, values_from = slope)
sub_df = slope_df[names(slope_df) != "location"]
scaled_slope_df = as_tibble(scale(sub_df))
slope_df = cbind(slope_df["location"], scaled_slope_df)
long_scaled = slope_df %>%
pivot_longer(
cols = names(slope_df)[names(slope_df) != "location"],
names_to = "clim_var",
values_to = "slope",
values_drop_na = TRUE
)
scaled_trendline_boxplots =  ggplot(data = long_scaled, aes(x = clim_var, y = slope)) +
geom_boxplot()+
labs(title = "variation in environmental variable slopes across locations",
subtitle = "standard scaling of the slopes per-variable")+
xlab("climate variable") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
ylab("scaled slope of time series trendline")
scaled_trendline_boxplots
